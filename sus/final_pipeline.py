# -*- coding: utf-8 -*-
"""final_pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-wAC8eFJNovXX9HnINrm_o9dvyxfgbsB
"""
from together import Together

import os
import json
import torch
from tqdm import tqdm
import torch.nn.functional as F
from pydub import AudioSegment
# from IPython.display import Markdown, HTML
from whisperspeech.pipeline import Pipeline

text_1='''
Ajji was on an outing with her daughter and daughter-in-law, Sumati and
Subhadra. One lived in Bangalore and the other in Mumbai. They were
returning the next day as they had used up all the leaves their offices had
given. The children would remain at Shiggaon though, with their
grandparents. Everyone was looking forward to this stage of the holidays. The
children because there would be no parents telling them what to do, to Ajji’s
delicious food and to fun outings with Ajja. The grandparents, too, were
looking forward to having the children to themselves. The rest of the year it
was only the two of them in the house.
As Ajji walked with the two younger women, they talked about how
difficult it was for them to manage their office work and the children. Ajji
listened silently. Then Sumati said,
‘But they are so good when they are with
you, Amma. How do you manage them so well?’ Subhadra nodded.
‘I have
read so many books and articles to find out about this, but nothing works the
way it is written in books.
’
Now Ajji said,
‘Do not always go by what you read in books. Learn to use
your life’s experiences, read between the lines.
’ Then she grinned and said,
‘Otherwise you will become like the people in the story about the donkey and
the stick!’
Sumati and Subhadra forgot they were at the temple and clamoured
together,
‘What is this story? Tell us!’ Ajji shook her head.
‘Now you are
behaving like children. But you are my children after all. All right, come join
us at night when I tell today’s story.
’
That night the two mothers were the first to appear to listen to the stories.
The children were surprised to see their mums, and Ajji started her story.
Aruna Marg was a busy road. It connected a number of villages to each other
and many people, animals and carts used it every day. Walking along that
road, a group of students discovered a rock which no one had bothered to look
at in many years.
‘Look!’ they told each other in excitement,
‘there is
something written on the rock. What can it mean?’
They called out to their teacher. When they examined the rock carefully,
they found the markings were actually little drawings. One showed a stick,
and the other a donkey.
By now a large crowd had gathered. Everyone was puzzled. What could
these strange drawings mean, they asked, scratching their heads. They
decided to go to the ashram of a wise sage nearby and ask him. But when they
trooped into the ashram, they found to their disappointment that the sage had
gone on a long pilgrimage. Only his young disciple was there, looking after
the cows and calves.
They asked the disciple if he could throw some light on the strange
drawings. Now this young man was not very bright. But like many foolish
people he loved to put on an air of learning and pretend to be very clever. He
examined the drawings carefully and minutely. Then he proclaimed,
‘It is
very simple. This is the drawing of a magic stick. The man with the stick is
the hero of this place. He died protecting this village centuries back. Each
person using this road must worship the rock and make an offering to it. The
one who ignores it will become a donkey!’
The villagers were astonished to hear this strange explanation. But they
were devout people and on that very day they set up a shrine around the rock.
They installed the foolish disciple as head priest in charge of taking offerings
from passing travellers. The disciple was pleased with his brainwave. Of
course he did not know what the silly drawings meant, but he no longer had to
run after calves and get kicked by angry cows in the ashram! He could sit by
the rock the whole day, taking his pick of the offerings to the rock and mutter
a few mumbo-jumbo prayers.
His happiness lasted a few months—till the wise old sage returned to the
ashram. The old sage was annoyed to find his disciple missing and his
beloved animals roaming around, uncared for. Then he looked into the
distance and saw a large crowd gathered by the road. He went to investigate,
and found his missing disciple there, looking happy and well fed, busy
accepting offerings for a rock. He stood watching for a while. Then he walked
up to the rock and closely examined the pictures. Without saying a word, he
picked up a stout iron rod and, to the astonishment of the gathered crowd,
started moving the rock. Many came forward to help him and when they had
been able to move the rock, they found a pot of gold under it!
The sage said to the people gathered around him: ‘The pictures meant you
had to move the rock with an iron rod and find the hidden money. If you
didn’t, you were all like donkeys. Y ou should not follow rituals and the words
of others blindly. Think for yourselves and understand why you are doing
what you do. If you had given this some thought, you would have recovered
this treasure many months ago. Instead, you wasted your time and money
making offerings to a rock and helping this greedy disciple of mine become
fat and make fools of you. This treasure belongs to all of us. Let’s use it to
keep this road in good repair so everyone can use it and go about their work
in peace.
’
The villagers hung their heads in shame for they realized how foolish they
had been. As for the disciple, he had to clean the cowsheds for many months
to atone for his greed.
'''
with open("story.txt","r") as f:
    text_1 = f.read()

print(text_1)

import re

def split_text_into_sentences(text):
    # Regular expression to match sentences ending with '.', '!', '?'
    sentences = re.split(r'(?<=[.!?])\s+', text)
    return sentences

def group_sentences_into_paragraphs(sentences, group_size=15):
    # Group the sentences into paragraphs of 'group_size' sentences each
    paragraphs = [' '.join(sentences[i:i+group_size]) for i in range(0, len(sentences), group_size)]
    return paragraphs

from together import Together
API_KEY="2790f2e2cb0b9d107fbe0398eaee980bdbc8b3fe23aec2b3bf182e1fd6a81e3d"
client=Together(api_key=API_KEY)
print("checkpoint....")
def generate_prompt(text,context):
  output=f'''
Given is the previous story:{context}
Given below is current story.You need to divide the current story into small chunks.For each chunk label them with their speaker and one of the following emotion [sadness, happiness, fear, anger, surprise , disgust or neutral] ,the speaker includes narator also .Divide into as many chunks as possible.Strictly Make sure you dont mix the sentence chunks of the characters dialogue and the narator dialogues.\nFor example sentence: he said "I am good" the sentence should be divided as he said and "I am good"\n.Emotion should be selected strictly from [sadness, happiness, fear, anger, surprise , disgust or neutral] directly without providing any reasoning,just provide one of the emotion label given to you directly.Do not miss any sentence strictly.\nSTORY:\n{text}.\n The output should be strictly in the form of list of json with each json having keys text_chunk,speaker and emotion.Nothing else should be provided except the json.
The output format:
[
  {{
    text_chunk:"sentence1"
    speaker:"speaker1"
    emotion:"emotion1"

  }}
  ,
  {{
    text_chunk:"sentence2"
    speaker:"speaker2"
    emotion:"emotion2"

  }}
]
  '''
  return output

def generate_response(model,client,text,context):
  prompt=generate_prompt(text,context)
  response = client.chat.completions.create(
        model=model,
        messages=[
            {"role": "assistant", "content": "You are an expert at predicting  speakers and emotions from a given text."},
            {"role": "user", "content": prompt}
        ]

  )
  response = response.choices[0].message.content.strip()
  return response
print("checkpoint....")
MODEL_NAME='meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo'

import time
def generate_annotations(paragraphs):
  time.sleep(10)
  answer=[]
  for i in range(len(paragraphs)):
    if i==0:
      response=generate_response(MODEL_NAME,client,paragraphs[0],'')
      answer.append(response)
    else:
      response=generate_response(MODEL_NAME,client,paragraphs[i],paragraphs[i-1])
      answer.append(response)
  return answer
# print("checkpoint....")
import json
def convert_to_json(ans):
  final=[]
  for a in ans:
    dic=json.loads(a)
    for d in dic:
      final.append(d)
  return final

def pipeline(text):
  sentences = split_text_into_sentences(text)
  paragraphs = group_sentences_into_paragraphs(sentences)
  ans=generate_annotations(paragraphs)
  return convert_to_json(ans)

output=pipeline(text_1)
print("checkpoint....")
from urllib.request import urlretrieve
import numpy as np
from langchain_community.embeddings import HuggingFaceBgeEmbeddings
from langchain_community.llms import HuggingFacePipeline
from langchain_community.document_loaders import PyPDFLoader
from langchain_community.document_loaders import PyPDFDirectoryLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain.chains import RetrievalQA
from langchain.prompts import PromptTemplate

from langchain.document_loaders import HuggingFaceDatasetLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import HuggingFaceEmbeddings
from langchain.vectorstores import FAISS
from transformers import AutoTokenizer, AutoModelForQuestionAnswering
from transformers import AutoTokenizer, pipeline
from langchain import HuggingFacePipeline
from langchain.chains import RetrievalQA
from langchain.document_loaders import TextLoader

from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.schema import Document
print("checkpoint....")
text_variable = text_1
documents = [Document(page_content=text_variable)]
text_splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=50)
docs = text_splitter.split_documents(documents)

model_id='sentence-transformers/all-MiniLM-l6-v2'

from langchain_community.llms import HuggingFaceHub

hf_token = "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"

llm = HuggingFaceHub(repo_id="meta-llama/Llama-3.2-3B",
                     huggingfacehub_api_token=hf_token,
                     model_kwargs={"temperature": 0.8})
print("checkpoint....")

huggingface_embeddings = HuggingFaceBgeEmbeddings(
    model_name=model_id,  # alternatively use "sentence-transformers/all-MiniLM-l6-v2" for a light and faster experience.
    model_kwargs={'device':'cpu'},
    encode_kwargs={'normalize_embeddings': True}
)

vectorstore = FAISS.from_documents(docs, huggingface_embeddings)

prompt_template = """Use the following pieces of context to answer the question at the end.:

{context}

Question: {question}

Helpful Answer:
"""

PROMPT = PromptTemplate(
 template=prompt_template, input_variables=["context", "question"]
)

retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 3})

retrievalQA = RetrievalQA.from_chain_type(
    llm=llm,
    chain_type="stuff",
    retriever=retriever,
    return_source_documents=True,
    chain_type_kwargs={"prompt": PROMPT}
)
print("checkpoint....")
def answer(query):
    result = retrievalQA.invoke({"query": query})
    return result['result']

def extract_character_desscription(output):
  speakers=list(set([l['speaker'] for l in output]))
  description=[{speaker: answer(f"Give a short description of the character {speaker}")} for speaker in speakers]
  return description

description=extract_character_desscription(output)

def predict_speaker(description):
  responses={}
  for d in description:
    speaker=str(list(d.keys())[0])
    description=d[speaker]
    prompt=f'''
    Given below the description of a character in a story.Choose which class does the character map to from the options
    ["old_male",
    "old_female",
    "adult_male",
    "adult_female",
    "kid_male",
    "kid_female",
    "narrator"]

    DESCRIPTION of {speaker}: {description}.
    Just provide the final mapping without any explanation


    '''
    response = client.chat.completions.create(
        model='meta-llama/Meta-Llama-3.1-405B-Instruct-Turbo',
        messages=[
            {"role": "assistant", "content": "You are an expert at predicting  speakers and emotions from a given text."},
            {"role": "user", "content": prompt}
        ])
    responses[speaker]=response.choices[0].message.content
  return responses

mapping=predict_speaker(description)

print(mapping)

print(output)
print("checkpoint....")
import os
import json
import torch
from tqdm import tqdm
import torch.nn.functional as F
from pydub import AudioSegment
# from IPython.display import Markdown, HTML
from whisperspeech.pipeline import Pipeline

pipe = Pipeline(t2s_ref='whisperspeech/whisperspeech:t2s-v1.95-small-8lang.model', s2a_ref='whisperspeech/whisperspeech:s2a-v1.95-medium-7lang.model')

data = output

print(data)

for entry in data:
    if entry['speaker'] in mapping:
        entry['speaker'] = mapping[entry['speaker']]

print(data)

print("checkpoint....")
import os
from tqdm import tqdm
os.makedirs('intermediate', exist_ok=False)
for i, entry in tqdm(enumerate(data), total=len(data), desc="Generating audio"):
  speaker=entry['speaker']
  speaker_file=''
  if 'old' in speaker:
    if 'male' in speaker:
      speaker_file="speakers/old_male.wav"

    elif'female' in speaker:
      speaker_file='speakers/old_male.wav'
    else:
      speaker_file='speakers/old_male.wav'

  elif 'adult' in speaker:
    if 'male' in speaker:
      speaker_file='speakers/adult_male.wav'
    elif 'female' in speaker:
      speaker_file='speakers/adult_female.wav'
    else:
      speaker_file='speakers/adult_male.wav'
  elif 'kid' in speaker:
    if 'male' in speaker:
      speaker_file='speakers/kid_male.wav'
    elif 'female' in speaker:
      speaker_file='speakers/kid_female.wav'
    else:
      speaker_file='speakers/kid_male.wav'

  else:
    speaker_file='speakers/adult_male.wav'

  pipe.generate_to_file(
        fname=f'intermediate/{i}_{entry["emotion"]}.wav',
        text=entry['text_chunk'],
        lang='en',
        cps=10,
        speaker=speaker_file
  )
print("checkpoint....")

print("checkpoint....")


"""# Testing"""


